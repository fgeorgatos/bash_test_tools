{
    "docs": [
        {
            "location": "/", 
            "text": "Bash Test Tools\n\n\nfor testing executables in a shell environment - here's a quick look...\n\n\n# A simple test for the \nfind\n executable\nsource bash_test_tools\n\nWORK=\n/tmp/work\n\n\nfunction setup\n{\n  mkdir -p \n$WORK\n\n  cd \n$WORK\n\n  touch some_file.txt\n}\n\nfunction teardown\n{\n  cd\n  rm -rf \n$WORK\n\n}\n\nfunction test_find_local_directory\n{\n  # Run\n  run \nfind ./\n\n  # Assert\n  assert_success\n  assert_output_contains \nsome_file.txt\n\n}\n\ntestrunner\n\n\n\n\n\n\nIntroduction\n\n\nBash Test Tools is intended to be a simple to use framework for testing executables inside\na shell environment. The framework allows extraction and assert operations on parameters\nsuch as \nstandard output\n, \nstandard error\n, \nexit code\n, \nexecution time\n, \nfile system\n and \nnetwork services\n.\n\n\nThe Bash Test Tools are suitable for performing high level tests on executables, i.e. \nsystem tests\n, treating an executable as\na black box, examining only the output and state of the executable and its environment. Typical domains of use could be to:\n\n\n\n\nverify complete \nuse cases\n\n\nidentify simple but critical failures, aka \nsmoke testing\n\n\nverify that documented behavior and \n--help\n is correct\n\n\ncollect \nperformance metrics\n  such as \nexecution time\n\n\n\n\nIn this document we will collectively call these test scenarios \nsystem tests\n.\n\n\nWorkflow\n\n\nThe workflow for implementing tests is as follows,\n\n\n\n\ncreate a bash script\n\n\nsource the \nbash_test_tools\n file\n\n\ndefine a function called \nsetup\n\n\ndefine a function called \nteardown\n\n\nimplement a series of test function, all must be named beginning with \ntest_\n (e.g. \ntest_foo\n).\n\n\nmust\n contain a run call, e.g. \nrun \"foo --some-opts args\"\n\n\nfollowed by at least one assert call, e.g. \nassert_success\n\n\n\n\n\n\nexecute the \ntestrunner\n function (it will magically run all test that have been defined)\n\n\n\n\nWhen the script is executed each test will be preceeded by a \nsetup\n followed by a \nteardown\n call.\nThis is sometimes inefficient but ensures that all tests run in isolation from each other.\nIf any one assert statement within a test function fails, the whole test will fail.\n\n\nCreating a Script\n\n\nFor demonstration purposes we are going to create a test for the UNIX command line tool\n\nfind\n, a tool that helps you list and search for files and directories.\nFirst we must fetch the source code and source the \nbash_test_tools\n file that is located in the root of the\nsource code directory\n\n\n$ # get the source code\n$ git clone https://github.com/videntifier/bash_test_tools.github\n$ cd bash_test_tools\n$ # start editing a new test in you favorite editor (here we use nano)\n$ nano test_find.sh\n\n\n\n\nAt the top of your test script add your typical \nshebang\n and\nsource the \nbash_test_tools\n file.\n\n\n#! /usr/bin/env bash\n# -*- coding: utf-8 -*-\nsource bash_test_tools\n\n\n\n\nBefore implementing our tests we must first define the \nsetup\n and \nteardown\n\nfunctions that take care of setting up and removing an environment for\nthe tests.\n\n\nTypically a \nsetup\n function will create a working directory and \ncd\n\ninto it.  The \nsetup\n may also start necessary services and/or provide test files to\noperate on. Here is an example setup function that creates a work directory and\nadds an empty test file:\n\n\nfunction setup\n{\n  mkdir -p work\n  cd work\n  touch some_file.txt\n}\n\n\n\n\nThe teardown function simply cleans up after the test has been performed and\ntypically may look as follows:\n\n\nfunction teardown\n{\n  cd ..\n  rm -rf work\n}\n\n\n\n\nWe can now define our first test. In this example lets find files in\nthe local directory, then assert that the operation was successfull and\nexited gracefully. Off course we also assert that \nfind\n has discovered\nour test file as expected,\n\n\nfunction test_find_local_directory\n{\n  # Run\n  run \nfind ./\n\n  # Assert\n  assert_success\n  assert_output_contains \nsome_file.txt\n\n}\n\n\n\n\nFinally it is necessary to execute the \ntestrunner\n, without it no tests will be processed.\nAdd the following line at the bottom of the script,\n\n\ntestrunner\n\n\n\n\nThe entire script now looks as follows,\n\n\n#! /usr/bin/env bash\n# -*- coding: utf-8 -*-\nsource bash_test_tools\n\nfunction setup\n{\n  mkdir -p work\n  cd work\n  touch some_file.txt\n}\n\nfunction teardown\n{\n  cd ..\n  rm -rf work\n}\n\nfunction test_find_local_directory\n{\n  # Run\n  run \nfind ./\n\n  # Assert\n  assert_success\n  assert_output_contains \nsome_file.txt\n\n}\n\ntestrunner\n\n\n\n\nExecute the script\n\n\nchmod u+x test_find.sh\n./test_find.sh\n\n\n\n\nand the output should look as follows,\n\n\n\n\nReview\n\n\nLets look in a little more detail what our test did.\nThe test defined did three things:\n\n\n\n\nFirst the \n\"find ./\"\n execution call was passed to the \nbash_test_tools\n \nrun\n function. Note the quotes \n\"find ./\"\n, they are necessary.\n\nRun\n will collect various metrics into global shell variables called \noutput\n, \nerror\n, \nexectime\n, \nreturnval\n and \nstrace\n - these will be addressed in detail later.\n\n\nThe second function call \nassert_success\n is a generic assert for healthy program termination with success. In fact the single \nassert_success\n call consists of a series of more granular asserts, called \nassert_terminated_normally\n, \nassert_exit_success\n and \nassert_no_error\n.\n\n\nterminated normally\n checks if executable exited normally (i.e. \nwithout crashing\n signals such as SIGENV).\n\n\nexit success\n checks the exit status is 0 (SUCCESS).\n\n\nno error\n will verify that nothing has been printed to standard error.\n\n\n\n\n\n\nThe third function call \nassert_output_contains\n simply verifies that the \nfind\n has correctly reported to \nstandard output\n that the test file \nsome_file.txt\n was found.\n\n\n\n\nScript Options\n\n\nThe framework automatically embeds options to the test script.\nHelp will be printed with optional argument \n-h\n.\n\n\n$ ./test_find.sh -h\n\ntest_find.sh - tests built on bash_test_tools\n\nUsage:  test_find.sh [OPTIONS]...\n\n  -l                 list all awailable tests\n  -t [TESTNAME]      run only test ending in TESTNAME\n  -o [TAP FILE]      write test results to TAP (test anything) file\n  -h                 print this help\n\n\n\n\nFor example, examine the test script provided inside the \nexamples\n directory.\n\n\n$ cd examples\n$ ./test_find.sh -l\ntest_find_delete\ntest_find_local_directory\ntest_find_txt_files\ntest_has_unix_conventions\ntest_invalid_file_or_directory\ntest_invalid_option\ntest_new_feature\n\n\n\n\nWe can specifically run only tests ending with the name \"_directory\"\n\n\n$ ./test_find.sh -t _directory\n----------------------------------------------------------------\nTEST FIND LOCAL DIRECTORY\nRunning: find ./\nExecTime: 0.004 seconds\nAssert: process terminated normally                          OK\nAssert: 'exit status' equal to 0                             OK\nAssert: 'stderror' is empty                                  OK\nAssert: 'stdoutput' contains 'some_file.txt'                 OK\n\nStatus - PASS\n----------------------------------------------------------------\nTEST INVALID FILE OR DIRECTORY\nRunning: find ./non_existing_path\nExecTime: 0.004 seconds\nAssert: process terminated normally                          OK\nAssert: 'exit status' not equal to 0                         OK\nAssert: 'stderror' not empty                                 OK\nAssert: 'stderror' contains 'No such file or directory'      OK\n\nStatus - PASS\n================================================================\nRan 2 tests - Failed 0\n\n\n\n\nAnd output test results in a portable format using the \nTest Anything Protocol\n,\n\n\n$ ./test_find.sh -t _directory -o result.tap\n$ cat result.tap\n**TODO**\n\n\n\n\nGeneric Tests\n\n\nbash_test_tools\n ships with a few \ngeneric\n tests that are appropriate for\ntesting common features.  Two very common features within UNIX environments\nare that executables typically accept \n--version\n and \n--help\n arguments.\nTo test an executable with a generic test for \n--version\n and \n--help\n options add\nthe following two lines to your script,\n\n\ngeneric has_unix_version \nfind\n\ngeneric has_unix_help \nfind\n\n\n\n\n\nThis will automatically construct tests on the executable \nfind\n\nthat check if the executable accepts version and help options.\nThey will assert that the program terminates healthily and if it actually prints\nsomething to sandard out.\n\n\n------------------------------------------------------\nTEST HAS UNIX HELP\nRunning: find --help\nExecTime: 0.004 seconds\nAssert: process terminated normally                OK\nAssert: 'exit status' equal to 0                   OK\nAssert: 'stderror' is empty                        OK\nAssert: 'stdout' not empty                         OK\nAssert: 'help' contains '--help'                   OK\n\nStatus - PASS\n------------------------------------------------------\nTEST HAS UNIX VERSION\nRunning: find --version\nExecTime: 0.005 seconds\nAssert: process terminated normally                OK\nAssert: 'exit status' equal to 0                   OK\nAssert: 'stderror' is empty                        OK\nAssert: 'stdout' not empty                         OK\nRunning: find --help\nExecTime: 0.004 seconds\nAssert: 'help' contains '--version'                OK\n\nStatus - PASS\n------------------------------------------------------\n\n\n\n\nNotice that \nhas_unix_version\n also checks if it has been\ndocumented in \n--help\n.\nThere is a third generic test that calls these two test,\nit is called \nhas_unix_convention\n, hence you can replace\nthe above two with a single line,\n\n\ngeneric has_unix_convention \nfind\n\n\n\n\n\nNot all command line tools do accept these options, we can take\na look at how this test fails when no such option is available.\n\nstrace\n is a tool that doesn't, here is how it fails,\n\n\n----------------------------------------------------------\nTEST HAS UNIX VERSION\nRunning: strace --version\nExecTime: 0.003 seconds\nAssert: process terminated normally                    OK\nAssert: 'exit status' equal to 0                     FAIL\nAssert: 'stderror' is empty                          FAIL\nAssert: 'stdout' not empty                           FAIL\nRunning: strace --help\nExecTime: 0.002 seconds\nAssert: 'help' contains '--version'                  FAIL\n\nStatus - FAIL\n==========================================================\nRan 1 tests - Failed 1\n\n\n\n\nTurns out \nstrace\n terminates gracefully, but does indicate\nthrough \nexit status\n and \nstandard error\n that the\ncall is unsupported. Writing tests that fail in this way\nis in fact one of the main points of software testing, to track through\n\ntest driven development\n if planned software features have been implemented\nor not.\n\n\nAs the \nbash_test_tools\n codebase developes we expect to add more generic\ntests that help catch commonplace conventions.\nTests for POSIX, Single UNIX and GNU protocols should be\nquite re-usable and ideal for writing generic tests. Please contribute some!\nLook for \n\"function generic_\"\n inside the \nbash_test_tools\n file to see how\na generic test is developed.\n\n\nAssert During Execution\n\n\nSo far we have only dealt with asserting conditions after an executable\nhas terminated.  However, sometimes we need to test for conditions\nduring execution. Some executables are for example designed to run as \nservices\n or \ndaemons\n.\nIn such situations we may need to execute assert statements while an executable is running\nin the background. \nbash_test_tools\n allow you to do this adding a\nset of assert statements to a background_assert queue. The following statement\nadds a tcp service check on port 1234 to the queue,\n\n\nadd_background_assert assert_service_on_port 1234\n\n\n\n\nThese asserts will then be executed during a backgrounded run statement.\nHere we start \nnetcat\n, a network diagnostic tool, and listen on port 1234\nfor 2 seconds before ending the process with a signalled SIGTERM.\n\n\nrun \nnc -l 1234\n background 2 SIGTERM\n\n\n\n\nThe queued assert statements are executed after the 2 second sleep, followed by\nthe signalled termination of the process. Some amount of sleep before executing\nasserts is necessary to allow the process or service to boot up or initialize.\nOff course the necessary sleep length will depend on the software and conditions that are being tested.\nThe whole test function that we have described looks like this,\n\n\nfunction test_nc_listen_on_port\n{\n  add_background_assert assert_service_on_port 1234\n  #run\n  run \nnc -l 1234\n background 2 SIGTERM\n  #assert\n  assert_terminated_normally\n  assert_no_error\n}\n\n\n\n\nWe have added a couple of more 'after execution' asserts to check for healthy termination of the software.\nWhen we execute the test we get the following output,\n\n\n------------------------------------------------------------------\nTEST NC LISTEN ON PORT\nRunning: nc -l 1234 (background 2 secs)\nAssert: service on port 1234                                   OK\nExecTime: 2.016 seconds\nAssert: process terminated normally                            OK\nAssert: 'stderror' is empty                                    OK\n\nStatus - PASS\n==================================================================\nRan 1 tests - Failed 0", 
            "title": "Introduction"
        }, 
        {
            "location": "/#bash-test-tools", 
            "text": "for testing executables in a shell environment - here's a quick look...  # A simple test for the  find  executable\nsource bash_test_tools\n\nWORK= /tmp/work \n\nfunction setup\n{\n  mkdir -p  $WORK \n  cd  $WORK \n  touch some_file.txt\n}\n\nfunction teardown\n{\n  cd\n  rm -rf  $WORK \n}\n\nfunction test_find_local_directory\n{\n  # Run\n  run  find ./ \n  # Assert\n  assert_success\n  assert_output_contains  some_file.txt \n}\n\ntestrunner", 
            "title": "Bash Test Tools"
        }, 
        {
            "location": "/#introduction", 
            "text": "Bash Test Tools is intended to be a simple to use framework for testing executables inside\na shell environment. The framework allows extraction and assert operations on parameters\nsuch as  standard output ,  standard error ,  exit code ,  execution time ,  file system  and  network services .  The Bash Test Tools are suitable for performing high level tests on executables, i.e.  system tests , treating an executable as\na black box, examining only the output and state of the executable and its environment. Typical domains of use could be to:   verify complete  use cases  identify simple but critical failures, aka  smoke testing  verify that documented behavior and  --help  is correct  collect  performance metrics   such as  execution time   In this document we will collectively call these test scenarios  system tests .", 
            "title": "Introduction"
        }, 
        {
            "location": "/#workflow", 
            "text": "The workflow for implementing tests is as follows,   create a bash script  source the  bash_test_tools  file  define a function called  setup  define a function called  teardown  implement a series of test function, all must be named beginning with  test_  (e.g.  test_foo ).  must  contain a run call, e.g.  run \"foo --some-opts args\"  followed by at least one assert call, e.g.  assert_success    execute the  testrunner  function (it will magically run all test that have been defined)   When the script is executed each test will be preceeded by a  setup  followed by a  teardown  call.\nThis is sometimes inefficient but ensures that all tests run in isolation from each other.\nIf any one assert statement within a test function fails, the whole test will fail.", 
            "title": "Workflow"
        }, 
        {
            "location": "/#creating-a-script", 
            "text": "For demonstration purposes we are going to create a test for the UNIX command line tool find , a tool that helps you list and search for files and directories.\nFirst we must fetch the source code and source the  bash_test_tools  file that is located in the root of the\nsource code directory  $ # get the source code\n$ git clone https://github.com/videntifier/bash_test_tools.github\n$ cd bash_test_tools\n$ # start editing a new test in you favorite editor (here we use nano)\n$ nano test_find.sh  At the top of your test script add your typical  shebang  and\nsource the  bash_test_tools  file.  #! /usr/bin/env bash\n# -*- coding: utf-8 -*-\nsource bash_test_tools  Before implementing our tests we must first define the  setup  and  teardown \nfunctions that take care of setting up and removing an environment for\nthe tests.  Typically a  setup  function will create a working directory and  cd \ninto it.  The  setup  may also start necessary services and/or provide test files to\noperate on. Here is an example setup function that creates a work directory and\nadds an empty test file:  function setup\n{\n  mkdir -p work\n  cd work\n  touch some_file.txt\n}  The teardown function simply cleans up after the test has been performed and\ntypically may look as follows:  function teardown\n{\n  cd ..\n  rm -rf work\n}  We can now define our first test. In this example lets find files in\nthe local directory, then assert that the operation was successfull and\nexited gracefully. Off course we also assert that  find  has discovered\nour test file as expected,  function test_find_local_directory\n{\n  # Run\n  run  find ./ \n  # Assert\n  assert_success\n  assert_output_contains  some_file.txt \n}  Finally it is necessary to execute the  testrunner , without it no tests will be processed.\nAdd the following line at the bottom of the script,  testrunner  The entire script now looks as follows,  #! /usr/bin/env bash\n# -*- coding: utf-8 -*-\nsource bash_test_tools\n\nfunction setup\n{\n  mkdir -p work\n  cd work\n  touch some_file.txt\n}\n\nfunction teardown\n{\n  cd ..\n  rm -rf work\n}\n\nfunction test_find_local_directory\n{\n  # Run\n  run  find ./ \n  # Assert\n  assert_success\n  assert_output_contains  some_file.txt \n}\n\ntestrunner  Execute the script  chmod u+x test_find.sh\n./test_find.sh  and the output should look as follows,", 
            "title": "Creating a Script"
        }, 
        {
            "location": "/#review", 
            "text": "Lets look in a little more detail what our test did.\nThe test defined did three things:   First the  \"find ./\"  execution call was passed to the  bash_test_tools   run  function. Note the quotes  \"find ./\" , they are necessary. Run  will collect various metrics into global shell variables called  output ,  error ,  exectime ,  returnval  and  strace  - these will be addressed in detail later.  The second function call  assert_success  is a generic assert for healthy program termination with success. In fact the single  assert_success  call consists of a series of more granular asserts, called  assert_terminated_normally ,  assert_exit_success  and  assert_no_error .  terminated normally  checks if executable exited normally (i.e.  without crashing  signals such as SIGENV).  exit success  checks the exit status is 0 (SUCCESS).  no error  will verify that nothing has been printed to standard error.    The third function call  assert_output_contains  simply verifies that the  find  has correctly reported to  standard output  that the test file  some_file.txt  was found.", 
            "title": "Review"
        }, 
        {
            "location": "/#script-options", 
            "text": "The framework automatically embeds options to the test script.\nHelp will be printed with optional argument  -h .  $ ./test_find.sh -h\n\ntest_find.sh - tests built on bash_test_tools\n\nUsage:  test_find.sh [OPTIONS]...\n\n  -l                 list all awailable tests\n  -t [TESTNAME]      run only test ending in TESTNAME\n  -o [TAP FILE]      write test results to TAP (test anything) file\n  -h                 print this help  For example, examine the test script provided inside the  examples  directory.  $ cd examples\n$ ./test_find.sh -l\ntest_find_delete\ntest_find_local_directory\ntest_find_txt_files\ntest_has_unix_conventions\ntest_invalid_file_or_directory\ntest_invalid_option\ntest_new_feature  We can specifically run only tests ending with the name \"_directory\"  $ ./test_find.sh -t _directory\n----------------------------------------------------------------\nTEST FIND LOCAL DIRECTORY\nRunning: find ./\nExecTime: 0.004 seconds\nAssert: process terminated normally                          OK\nAssert: 'exit status' equal to 0                             OK\nAssert: 'stderror' is empty                                  OK\nAssert: 'stdoutput' contains 'some_file.txt'                 OK\n\nStatus - PASS\n----------------------------------------------------------------\nTEST INVALID FILE OR DIRECTORY\nRunning: find ./non_existing_path\nExecTime: 0.004 seconds\nAssert: process terminated normally                          OK\nAssert: 'exit status' not equal to 0                         OK\nAssert: 'stderror' not empty                                 OK\nAssert: 'stderror' contains 'No such file or directory'      OK\n\nStatus - PASS\n================================================================\nRan 2 tests - Failed 0  And output test results in a portable format using the  Test Anything Protocol ,  $ ./test_find.sh -t _directory -o result.tap\n$ cat result.tap\n**TODO**", 
            "title": "Script Options"
        }, 
        {
            "location": "/#generic-tests", 
            "text": "bash_test_tools  ships with a few  generic  tests that are appropriate for\ntesting common features.  Two very common features within UNIX environments\nare that executables typically accept  --version  and  --help  arguments.\nTo test an executable with a generic test for  --version  and  --help  options add\nthe following two lines to your script,  generic has_unix_version  find \ngeneric has_unix_help  find   This will automatically construct tests on the executable  find \nthat check if the executable accepts version and help options.\nThey will assert that the program terminates healthily and if it actually prints\nsomething to sandard out.  ------------------------------------------------------\nTEST HAS UNIX HELP\nRunning: find --help\nExecTime: 0.004 seconds\nAssert: process terminated normally                OK\nAssert: 'exit status' equal to 0                   OK\nAssert: 'stderror' is empty                        OK\nAssert: 'stdout' not empty                         OK\nAssert: 'help' contains '--help'                   OK\n\nStatus - PASS\n------------------------------------------------------\nTEST HAS UNIX VERSION\nRunning: find --version\nExecTime: 0.005 seconds\nAssert: process terminated normally                OK\nAssert: 'exit status' equal to 0                   OK\nAssert: 'stderror' is empty                        OK\nAssert: 'stdout' not empty                         OK\nRunning: find --help\nExecTime: 0.004 seconds\nAssert: 'help' contains '--version'                OK\n\nStatus - PASS\n------------------------------------------------------  Notice that  has_unix_version  also checks if it has been\ndocumented in  --help .\nThere is a third generic test that calls these two test,\nit is called  has_unix_convention , hence you can replace\nthe above two with a single line,  generic has_unix_convention  find   Not all command line tools do accept these options, we can take\na look at how this test fails when no such option is available. strace  is a tool that doesn't, here is how it fails,  ----------------------------------------------------------\nTEST HAS UNIX VERSION\nRunning: strace --version\nExecTime: 0.003 seconds\nAssert: process terminated normally                    OK\nAssert: 'exit status' equal to 0                     FAIL\nAssert: 'stderror' is empty                          FAIL\nAssert: 'stdout' not empty                           FAIL\nRunning: strace --help\nExecTime: 0.002 seconds\nAssert: 'help' contains '--version'                  FAIL\n\nStatus - FAIL\n==========================================================\nRan 1 tests - Failed 1  Turns out  strace  terminates gracefully, but does indicate\nthrough  exit status  and  standard error  that the\ncall is unsupported. Writing tests that fail in this way\nis in fact one of the main points of software testing, to track through test driven development  if planned software features have been implemented\nor not.  As the  bash_test_tools  codebase developes we expect to add more generic\ntests that help catch commonplace conventions.\nTests for POSIX, Single UNIX and GNU protocols should be\nquite re-usable and ideal for writing generic tests. Please contribute some!\nLook for  \"function generic_\"  inside the  bash_test_tools  file to see how\na generic test is developed.", 
            "title": "Generic Tests"
        }, 
        {
            "location": "/#assert-during-execution", 
            "text": "So far we have only dealt with asserting conditions after an executable\nhas terminated.  However, sometimes we need to test for conditions\nduring execution. Some executables are for example designed to run as  services  or  daemons .\nIn such situations we may need to execute assert statements while an executable is running\nin the background.  bash_test_tools  allow you to do this adding a\nset of assert statements to a background_assert queue. The following statement\nadds a tcp service check on port 1234 to the queue,  add_background_assert assert_service_on_port 1234  These asserts will then be executed during a backgrounded run statement.\nHere we start  netcat , a network diagnostic tool, and listen on port 1234\nfor 2 seconds before ending the process with a signalled SIGTERM.  run  nc -l 1234  background 2 SIGTERM  The queued assert statements are executed after the 2 second sleep, followed by\nthe signalled termination of the process. Some amount of sleep before executing\nasserts is necessary to allow the process or service to boot up or initialize.\nOff course the necessary sleep length will depend on the software and conditions that are being tested.\nThe whole test function that we have described looks like this,  function test_nc_listen_on_port\n{\n  add_background_assert assert_service_on_port 1234\n  #run\n  run  nc -l 1234  background 2 SIGTERM\n  #assert\n  assert_terminated_normally\n  assert_no_error\n}  We have added a couple of more 'after execution' asserts to check for healthy termination of the software.\nWhen we execute the test we get the following output,  ------------------------------------------------------------------\nTEST NC LISTEN ON PORT\nRunning: nc -l 1234 (background 2 secs)\nAssert: service on port 1234                                   OK\nExecTime: 2.016 seconds\nAssert: process terminated normally                            OK\nAssert: 'stderror' is empty                                    OK\n\nStatus - PASS\n==================================================================\nRan 1 tests - Failed 0", 
            "title": "Assert During Execution"
        }, 
        {
            "location": "/Assert_API/", 
            "text": "Assert API\n\n\nCurrently the following assert functions have been implemented, Some useful asserts are probably still missing, so please contribute or ask for help.\nIf you want to develop, please take a look at functions beginning with \nassert_\n\nin the \nbash_test_tools\n file.\n\n\nvariables\n\n\nThe most elementary assert calls operate on environment variables within the shell.\nTypically more specific assert statements, such as \nassert_no_error\n are composed of one or more of these\nmore elementary asserts.\n\n\nassert_contains\n\n\n# Asserts that $var contains sub-string $string\n# assert_contains \n$var\n \n$string\n    [var-alias [string-alias]]\n# example: \nassert_contains \n$output\n \nHello World\n\n# or\nassert_contains \n$output\n \nHello World\n \nstandard output\n\n\n\n\n\nassert_not_contains\n\n\n# Asserts that $var does not contain a sub-string $string\n# assert_not_contains \n$string\n [var-alias [string-alias]]\n# example:\nassert_not_contains \n$output\n \nHello World\n\n# or\nassert_not_contains \n$output\n \nHello World\n \nstandard output\n\n\n\n\n\nassert_equal\n\n\n# Asserts that $var1 equals $var2 - works on both numeric and strings\n# assert_equal \n$var1\n \n$var2\n    [var1-alias [var2-alias]]\n# example: \nassert_equal \n$output\n \nHello World\n\nassert_equal \n$output1\n \n$output2\n \nrun 1 output\n \nrun 2 output\n\n\n\n\n\nassert_not_equal\n\n\n# Asserts that $var1 does not equal $var2 - works on both numeric and strings\n# assert_not_equal \n$var1\n \n$var2\n    [var1-alias [var2-alias]]\n# example: \nassert_not_equal \n$output\n \nHello World\n\n# or\nassert_equal \n$output1\n \n$output2\n \nrun 1 output\n \nrun 2 output\n\n\n\n\n\nassert_greater_than\n\n\n# Asserts that $var1 is greater than $var2 - works on numeric\n# assert_greater_than \n$var1\n \n$var2\n    [var1-alias [var2-alias]]\n# example: \nassert_greater_than \n$thread_count\n \n4\n \nthread count\n\n\n\n\n\nassert_less_than\n\n\n# Asserts that $var1 is less than $var2 - works on numeric\n# assert_less_than \n$var1\n \n$var2\n    [var1-alias [var2-alias]]\n# example: \nassert_less_than \n$thread_count\n \n4\n \nthread count\n\n\n\n\n\nassert_empty\n\n\n# Asserts that $var is \n or not set\n# assert_empty \n$var\n [var-alias]\n# example: \nassert_empty \n$error\n \nstd error\n\n\n\n\n\nassert_not_empty\n\n\n# Asserts that $var is not \n\n# assert_not_empty \n$var\n [var-alias]\n# example: \nassert_not_empty \n$output\n \nstd output\n\n\n\n\n\nassert_matches_regex\n\n\n# Asserts that $var matches regular expression $regex\n# assert_matches \n$var\n \n$regex\n [var-alias]\n# example: \nassert_matches_regex \n$output\n \n^[0-9]+\\.[0-9]+\\.[0-9]+\n \noutput version number\n\n# i.e. asserts that $output begins with ##.##.## version style numerics\n\n\n\n\noutput\n\n\nThese asserts apply specifically to the \nstandard output\n, variable \noutput\n.\n\n\nassert_output_contains\n\n\n# Asserts that $output contains a sub-string $string [string-alias]\n# assert_output_contains \n$string\n\n# example:\nassert_output_contains \nHello World\n\n\n\n\n\nassert_output_not_contains\n\n\n# Asserts that $output does not contain a sub-string $string [string-alias]\n# assert_output_not_contains \n$string\n\n# example:\nassert_output_not_contains \nHello world\n\n\n\n\n\nassert_has_output\n\n\n# Asserts that $output is not empty != \n\n# assert_has_output\n# example:\nassert_has_output\n\n\n\n\nassert_no_output\n\n\n# Asserts that $output is empty == \n\n# assert_no_output\n# example:\nassert_no_output\n\n\n\n\nerror\n\n\nThese asserts apply specifically to the \nstandard error\n, variable \nerror\n\n\nassert_error_contains\n\n\n# Asserts that $error contains a sub-string $string [string-alias]\n# assert_error_contains \n$string\n\n# example:\nassert_error_contains \ncould not open file\n\n\n\n\n\nassert_has_error\n\n\n# Asserts that $error is not empty != \n\n# assert_has_error\n# example:\nassert_has_error\n\n\n\n\nassert_no_error\n\n\n# Asserts that $error is empty == \n\n# assert_no_error\n# example:\nassert_no_error\n\n\n\n\ntermination\n\n\nThese asserts apply specifically to the variables \nreturnval\n, \nerror\n and \nstrace\n.  They evaluate the conditions by which the executable terminated.\n\n\nassert_exit_success\n\n\n# Asserts that $returnval is equal to 0 (SUCCESS)\n# assert_exit_success\n# example:\nassert_exit_succes\n\n\n\n\nassert_exit_fail\n\n\n# Asserts that $returnval is not equal to 0 (FAIL)\n# assert_exit_fail\n# example:\nassert_exit_fail\n\n\n\n\nassert_terminated_normally\n\n\n# Essentailly asserts that the executable exited without crashing.\n# Asserts that $strace does no include substring \ntgkill\n\n# assert_terminated_normally\n# example:\nassert_terminated_normally\n\n\n\n\nassert_success\n\n\n# Asserts healthy success behavior\n# Calls assert_terminated_normally, assert_exit_success, assert_no_error\n# example:\nassert_success\n\n\n\n\nassert_fail\n\n\n# Asserts healthy fail behavior\n# Calls assert_terminated_normally, assert_exit_fail, assert_has_error\n# example:\nassert_fail\n\n\n\n\nfile system\n\n\nThese asserts apply to files and directories\n\n\nassert_file_exists\n\n\n# asserts that file exists\n# assert_file_exists \n$file_path\n\n# example:\nassert_file_exists \n$file_path\n\n\n\n\n\nassert_file_not_exists\n\n\n# asserts that file does not exist\n# assert_file_not_exists \n$file_path\n\n# example:\nassert_file_not_exists \n$file_path\n\n\n\n\n\nassert_dir_exists\n\n\n# asserts that a directory exists\n# assert_dir_exists \n$dir_path\n\n# example:\nassert_dir_exists \n$dir_path\n\n\n\n\n\nassert_tree_equal\n\n\n# asserts that two directory trees are the same\n# assert_tree_equal \n$dir1\n \n$dir2\n\n# example:\nassert_tree_equal \n/some/dir1\n \n/some/other/dir2\n\n\n\n\n\nassert_tree_not_equal\n\n\n# asserts that two directory trees are not the same\n# assert_tree_not_equal \n$dir1\n \n$dir2\n\n# example:\nassert_tree_not_equal \n/some/dir1\n \n/some/other/dir2\n\n\n\n\n\nservices\n\n\nThese asserts apply to services, typically network services.\n\n\nassert_service_on_port\n\n\n# asserts that a network service is listening on port $port\n# assert_service_on_port \n$port\n\n# example:\nassert_service_on_port \n8000", 
            "title": "Assert API"
        }, 
        {
            "location": "/Assert_API/#assert-api", 
            "text": "Currently the following assert functions have been implemented, Some useful asserts are probably still missing, so please contribute or ask for help.\nIf you want to develop, please take a look at functions beginning with  assert_ \nin the  bash_test_tools  file.", 
            "title": "Assert API"
        }, 
        {
            "location": "/Assert_API/#variables", 
            "text": "The most elementary assert calls operate on environment variables within the shell.\nTypically more specific assert statements, such as  assert_no_error  are composed of one or more of these\nmore elementary asserts.  assert_contains  # Asserts that $var contains sub-string $string\n# assert_contains  $var   $string     [var-alias [string-alias]]\n# example: \nassert_contains  $output   Hello World \n# or\nassert_contains  $output   Hello World   standard output   assert_not_contains  # Asserts that $var does not contain a sub-string $string\n# assert_not_contains  $string  [var-alias [string-alias]]\n# example:\nassert_not_contains  $output   Hello World \n# or\nassert_not_contains  $output   Hello World   standard output   assert_equal  # Asserts that $var1 equals $var2 - works on both numeric and strings\n# assert_equal  $var1   $var2     [var1-alias [var2-alias]]\n# example: \nassert_equal  $output   Hello World \nassert_equal  $output1   $output2   run 1 output   run 2 output   assert_not_equal  # Asserts that $var1 does not equal $var2 - works on both numeric and strings\n# assert_not_equal  $var1   $var2     [var1-alias [var2-alias]]\n# example: \nassert_not_equal  $output   Hello World \n# or\nassert_equal  $output1   $output2   run 1 output   run 2 output   assert_greater_than  # Asserts that $var1 is greater than $var2 - works on numeric\n# assert_greater_than  $var1   $var2     [var1-alias [var2-alias]]\n# example: \nassert_greater_than  $thread_count   4   thread count   assert_less_than  # Asserts that $var1 is less than $var2 - works on numeric\n# assert_less_than  $var1   $var2     [var1-alias [var2-alias]]\n# example: \nassert_less_than  $thread_count   4   thread count   assert_empty  # Asserts that $var is   or not set\n# assert_empty  $var  [var-alias]\n# example: \nassert_empty  $error   std error   assert_not_empty  # Asserts that $var is not  \n# assert_not_empty  $var  [var-alias]\n# example: \nassert_not_empty  $output   std output   assert_matches_regex  # Asserts that $var matches regular expression $regex\n# assert_matches  $var   $regex  [var-alias]\n# example: \nassert_matches_regex  $output   ^[0-9]+\\.[0-9]+\\.[0-9]+   output version number \n# i.e. asserts that $output begins with ##.##.## version style numerics", 
            "title": "variables"
        }, 
        {
            "location": "/Assert_API/#output", 
            "text": "These asserts apply specifically to the  standard output , variable  output .  assert_output_contains  # Asserts that $output contains a sub-string $string [string-alias]\n# assert_output_contains  $string \n# example:\nassert_output_contains  Hello World   assert_output_not_contains  # Asserts that $output does not contain a sub-string $string [string-alias]\n# assert_output_not_contains  $string \n# example:\nassert_output_not_contains  Hello world   assert_has_output  # Asserts that $output is not empty !=  \n# assert_has_output\n# example:\nassert_has_output  assert_no_output  # Asserts that $output is empty ==  \n# assert_no_output\n# example:\nassert_no_output", 
            "title": "output"
        }, 
        {
            "location": "/Assert_API/#error", 
            "text": "These asserts apply specifically to the  standard error , variable  error  assert_error_contains  # Asserts that $error contains a sub-string $string [string-alias]\n# assert_error_contains  $string \n# example:\nassert_error_contains  could not open file   assert_has_error  # Asserts that $error is not empty !=  \n# assert_has_error\n# example:\nassert_has_error  assert_no_error  # Asserts that $error is empty ==  \n# assert_no_error\n# example:\nassert_no_error", 
            "title": "error"
        }, 
        {
            "location": "/Assert_API/#termination", 
            "text": "These asserts apply specifically to the variables  returnval ,  error  and  strace .  They evaluate the conditions by which the executable terminated.  assert_exit_success  # Asserts that $returnval is equal to 0 (SUCCESS)\n# assert_exit_success\n# example:\nassert_exit_succes  assert_exit_fail  # Asserts that $returnval is not equal to 0 (FAIL)\n# assert_exit_fail\n# example:\nassert_exit_fail  assert_terminated_normally  # Essentailly asserts that the executable exited without crashing.\n# Asserts that $strace does no include substring  tgkill \n# assert_terminated_normally\n# example:\nassert_terminated_normally  assert_success  # Asserts healthy success behavior\n# Calls assert_terminated_normally, assert_exit_success, assert_no_error\n# example:\nassert_success  assert_fail  # Asserts healthy fail behavior\n# Calls assert_terminated_normally, assert_exit_fail, assert_has_error\n# example:\nassert_fail", 
            "title": "termination"
        }, 
        {
            "location": "/Assert_API/#file-system", 
            "text": "These asserts apply to files and directories  assert_file_exists  # asserts that file exists\n# assert_file_exists  $file_path \n# example:\nassert_file_exists  $file_path   assert_file_not_exists  # asserts that file does not exist\n# assert_file_not_exists  $file_path \n# example:\nassert_file_not_exists  $file_path   assert_dir_exists  # asserts that a directory exists\n# assert_dir_exists  $dir_path \n# example:\nassert_dir_exists  $dir_path   assert_tree_equal  # asserts that two directory trees are the same\n# assert_tree_equal  $dir1   $dir2 \n# example:\nassert_tree_equal  /some/dir1   /some/other/dir2   assert_tree_not_equal  # asserts that two directory trees are not the same\n# assert_tree_not_equal  $dir1   $dir2 \n# example:\nassert_tree_not_equal  /some/dir1   /some/other/dir2", 
            "title": "file system"
        }, 
        {
            "location": "/Assert_API/#services", 
            "text": "These asserts apply to services, typically network services.  assert_service_on_port  # asserts that a network service is listening on port $port\n# assert_service_on_port  $port \n# example:\nassert_service_on_port  8000", 
            "title": "services"
        }
    ]
}